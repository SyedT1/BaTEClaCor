{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoModelForMaskedLM,XLMRobertaForSequenceClassification","metadata":{"id":"2e0f75c3","outputId":"1968999e-09e5-4f8d-fb47-377c1b235879","papermill":{"duration":13.349991,"end_time":"2023-07-25T16:06:48.929213","exception":false,"start_time":"2023-07-25T16:06:35.579222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:38:41.609530Z","iopub.execute_input":"2023-09-10T23:38:41.609887Z","iopub.status.idle":"2023-09-10T23:38:56.809978Z","shell.execute_reply.started":"2023-09-10T23:38:41.609856Z","shell.execute_reply":"2023-09-10T23:38:56.809018Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = 'xlm-roberta-base'\ntokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\nmodel = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\")\n# Define device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"id":"4913d932","outputId":"5eb3dd9b-5b04-4803-ae2a-b601b8da7ba0","papermill":{"duration":4.173444,"end_time":"2023-07-25T16:06:53.106774","exception":false,"start_time":"2023-07-25T16:06:48.933330","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:38:56.812128Z","iopub.execute_input":"2023-09-10T23:38:56.812825Z","iopub.status.idle":"2023-09-10T23:39:07.698675Z","shell.execute_reply.started":"2023-09-10T23:38:56.812791Z","shell.execute_reply":"2023-09-10T23:39:07.697614Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6e8439e3835493aad51cd20d60aaf6e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85cce1af64fb4fe3883ef79d1faa4c69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af1cf35e01f4ea38de4b3f399de250b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fd94e9177a04ed68cfa5db88bba6d2b"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain_url = '/kaggle/input/bec-dataset/train_data.csv'\ntest_url = '/kaggle/input/bec-dataset/test_data.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)","metadata":{"id":"b0560ae3","papermill":{"duration":0.132745,"end_time":"2023-07-25T16:06:53.244675","exception":false,"start_time":"2023-07-25T16:06:53.111930","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:39:07.699977Z","iopub.execute_input":"2023-09-10T23:39:07.700367Z","iopub.status.idle":"2023-09-10T23:39:08.233207Z","shell.execute_reply.started":"2023-09-10T23:39:07.700330Z","shell.execute_reply":"2023-09-10T23:39:08.232262Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"STOPWORDS = set([word.strip() for word in stop_words_df['words']])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:39:08.235950Z","iopub.execute_input":"2023-09-10T23:39:08.236571Z","iopub.status.idle":"2023-09-10T23:39:08.247009Z","shell.execute_reply.started":"2023-09-10T23:39:08.236536Z","shell.execute_reply":"2023-09-10T23:39:08.246086Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess(x):\n    html_pattern = re.compile('<.*?>')\n    x = html_pattern.sub(r'', x)\n    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n    return x\ndf_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\ndf_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:39:08.248396Z","iopub.execute_input":"2023-09-10T23:39:08.250020Z","iopub.status.idle":"2023-09-10T23:39:08.309128Z","shell.execute_reply.started":"2023-09-10T23:39:08.249967Z","shell.execute_reply":"2023-09-10T23:39:08.308308Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_no = 5\n\n# Prepare the training data\ntrain_texts = df_train['Comment'].tolist()\ntrain_labels = df_train['Error'].tolist()\n\ntest_texts = df_test['Comment'].tolist()\ntest_labels = df_test['Error'].tolist()","metadata":{"id":"6b9dc3e4","papermill":{"duration":0.018204,"end_time":"2023-07-25T16:06:53.268005","exception":false,"start_time":"2023-07-25T16:06:53.249801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:39:08.310222Z","iopub.execute_input":"2023-09-10T23:39:08.310524Z","iopub.status.idle":"2023-09-10T23:39:08.316634Z","shell.execute_reply.started":"2023-09-10T23:39:08.310494Z","shell.execute_reply":"2023-09-10T23:39:08.315661Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the training texts\ntrain_encodings = tokenizer(train_texts, truncation=True, max_length=128,\n        padding='max_length', return_tensors = 'pt')\n\n# Convert the labels to tensors\ntrain_labels = torch.tensor(train_labels)\n\n# Create a PyTorch dataset\ntrain_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'],\n                                               train_encodings['attention_mask'],\n                                               train_labels)\n\n# Create a data loader\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nmodel = model.to(device)","metadata":{"id":"c68abf8e","outputId":"fc006e00-bc36-49f7-9041-3cc6a300504b","papermill":{"duration":11.003131,"end_time":"2023-07-25T16:07:04.276102","exception":false,"start_time":"2023-07-25T16:06:53.272971","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:39:08.317975Z","iopub.execute_input":"2023-09-10T23:39:08.318962Z","iopub.status.idle":"2023-09-10T23:39:15.702736Z","shell.execute_reply.started":"2023-09-10T23:39:08.318930Z","shell.execute_reply":"2023-09-10T23:39:15.701643Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n\nfrom tqdm.notebook import tqdm\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\n\n# Set the model to training mode\nmodel.train()\n\n# Define the optimizer and loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nlosses = []\naccuracies = []  # To store accuracy per epoch\nnum_epochs = 5\n# Training loop\nfor epoch in tqdm(range(num_epochs)):  # Number of training epochs\n    running_loss = 0.0\n    predicted_labels = []  # To store predicted labels for accuracy calculation\n    true_labels = []  # To store true labels for accuracy calculation\n\n    for batch in tqdm(train_loader):\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        labels = batch[2].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Convert logits to predicted labels\n        _, predicted = torch.max(logits, dim=1)\n        predicted_labels.extend(predicted.cpu().tolist())\n        true_labels.extend(labels.cpu().tolist())\n\n    epoch_loss = running_loss / len(train_loader)\n    losses.append(epoch_loss)\n\n    # Calculate and store accuracy\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    accuracies.append(accuracy)\n\n    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {accuracy:.4f}')\n\n# Save the model\ntorch.save(model.state_dict(), 'model.pth')\n\n","metadata":{"id":"eedb3a9c","outputId":"81f0d82e-5d90-4271-e5cf-71638bf8bc98","papermill":{"duration":668.41198,"end_time":"2023-07-25T16:18:12.693572","exception":false,"start_time":"2023-07-25T16:07:04.281592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:47:13.436536Z","iopub.execute_input":"2023-09-10T23:47:13.436931Z","iopub.status.idle":"2023-09-11T00:04:35.807529Z","shell.execute_reply.started":"2023-09-10T23:47:13.436900Z","shell.execute_reply":"2023-09-11T00:04:35.806419Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88064f72eef944619bb6e2d9a88e32f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16ad095dad674120a3a3bbb5c7999036"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5 - Loss: 0.5294 - Accuracy: 0.7478\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74af6583d4e24daf9e28579e222d8b18"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/5 - Loss: 0.4822 - Accuracy: 0.7815\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02a1deee659d495a8e3f7ab1111c388a"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/5 - Loss: 0.4385 - Accuracy: 0.8032\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a3927e6848e47039a7d0ab4599578a6"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/5 - Loss: 0.4005 - Accuracy: 0.8259\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f033265397814eed9899ad8e28d467ff"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/5 - Loss: 0.3658 - Accuracy: 0.8439\n","output_type":"stream"}]},{"cell_type":"code","source":"#dgfdgdfgdgffdgdfd1212jhkhk","metadata":{"papermill":{"duration":0.014424,"end_time":"2023-07-25T16:18:12.713695","exception":false,"start_time":"2023-07-25T16:18:12.699271","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-10T23:47:05.101347Z","iopub.status.idle":"2023-09-10T23:47:05.102466Z","shell.execute_reply.started":"2023-09-10T23:47:05.102278Z","shell.execute_reply":"2023-09-10T23:47:05.102297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\ndef predict_labels(text):\n    train_encodings = tokenizer(text, truncation=True, max_length=128,\n        padding='max_length', return_tensors = 'pt')\n    input_ids = train_encodings['input_ids'].to(device)\n    attention_mask = train_encodings['attention_mask'].to(device)\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Disable gradient calculation\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n\n    logits = outputs.logits\n    probabilities = torch.softmax(logits, dim=1)\n    predicted_class = torch.argmax(probabilities, dim=1)\n    \n\n    return predicted_class.item(), probabilities[:,1].item()","metadata":{"id":"1243273c","papermill":{"duration":0.69644,"end_time":"2023-07-25T16:18:13.415572","exception":false,"start_time":"2023-07-25T16:18:12.719132","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:05:24.143111Z","iopub.execute_input":"2023-09-11T00:05:24.143481Z","iopub.status.idle":"2023-09-11T00:05:24.152877Z","shell.execute_reply.started":"2023-09-11T00:05:24.143452Z","shell.execute_reply":"2023-09-11T00:05:24.151778Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"predicted_labels = []\npredicted_probs = []\nfor text in tqdm(test_texts):\n    predicted_label, prob = predict_labels(text)\n    predicted_labels.append(predicted_label)\n    predicted_probs.append(prob)\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(test_labels, predicted_labels)\n# f1 = f1_score(test_labels, predicted_labels)\n# roc_auc = roc_auc_score(test_labels, predicted_probs)\n\nprint('Accuracy:', accuracy)\n# print('F1 Score:', f1)\n# print('ROC-AUC:', roc_auc)","metadata":{"id":"d57fe764","outputId":"d7e9495a-7096-413f-cc6e-0f3e69cdc327","papermill":{"duration":56.127329,"end_time":"2023-07-25T16:19:09.548653","exception":false,"start_time":"2023-07-25T16:18:13.421324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:05:25.638635Z","iopub.execute_input":"2023-09-11T00:05:25.639328Z","iopub.status.idle":"2023-09-11T00:05:56.151723Z","shell.execute_reply.started":"2023-09-11T00:05:25.639295Z","shell.execute_reply":"2023-09-11T00:05:56.150780Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2010 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c0ff0cb2713402bb485648232d6a0db"}},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.7681592039800995\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Accuracy:', accuracy)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:05:56.154006Z","iopub.execute_input":"2023-09-11T00:05:56.154768Z","iopub.status.idle":"2023-09-11T00:05:56.160645Z","shell.execute_reply.started":"2023-09-11T00:05:56.154712Z","shell.execute_reply":"2023-09-11T00:05:56.159693Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Accuracy: 0.7681592039800995\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, classification_report\n\nprint('\\nThe Classification Report is as follows\\n')\nprint(classification_report(test_labels, predicted_labels, digits = 4))","metadata":{"papermill":{"duration":0.031899,"end_time":"2023-07-25T16:19:09.586107","exception":false,"start_time":"2023-07-25T16:19:09.554208","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:05:56.162307Z","iopub.execute_input":"2023-09-11T00:05:56.163081Z","iopub.status.idle":"2023-09-11T00:05:56.190177Z","shell.execute_reply.started":"2023-09-11T00:05:56.163042Z","shell.execute_reply":"2023-09-11T00:05:56.189064Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\nThe Classification Report is as follows\n\n              precision    recall  f1-score   support\n\n           0     0.7694    0.8578    0.8112      1167\n           1     0.7659    0.6441    0.6997       843\n\n    accuracy                         0.7682      2010\n   macro avg     0.7676    0.7509    0.7555      2010\nweighted avg     0.7679    0.7682    0.7644      2010\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}