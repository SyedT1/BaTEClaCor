{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoModelForMaskedLM,XLMRobertaForSequenceClassification","metadata":{"id":"2e0f75c3","outputId":"1968999e-09e5-4f8d-fb47-377c1b235879","papermill":{"duration":13.349991,"end_time":"2023-07-25T16:06:48.929213","exception":false,"start_time":"2023-07-25T16:06:35.579222","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:46:35.768224Z","iopub.execute_input":"2023-09-11T00:46:35.768803Z","iopub.status.idle":"2023-09-11T00:46:59.556057Z","shell.execute_reply.started":"2023-09-11T00:46:35.768758Z","shell.execute_reply":"2023-09-11T00:46:59.555071Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = 'xlm-roberta-base'\ntokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\nmodel = XLMRobertaForSequenceClassification.from_pretrained(\"xlm-roberta-base\",num_labels=5)\n# Define device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"id":"4913d932","outputId":"5eb3dd9b-5b04-4803-ae2a-b601b8da7ba0","papermill":{"duration":4.173444,"end_time":"2023-07-25T16:06:53.106774","exception":false,"start_time":"2023-07-25T16:06:48.933330","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:46:59.558004Z","iopub.execute_input":"2023-09-11T00:46:59.558400Z","iopub.status.idle":"2023-09-11T00:47:09.756453Z","shell.execute_reply.started":"2023-09-11T00:46:59.558353Z","shell.execute_reply":"2023-09-11T00:47:09.755666Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945c088143104907819e6a5e895da2c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f05bdbae3c024d6b8555354f4c636045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e0e24a993f4d72895e9756f7e9285e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f0ab631c0f34e109f16b134be05f591"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ntrain_url = '/kaggle/input/bec-dataset/train_data.csv'\ntest_url = '/kaggle/input/bec-dataset/test_data.csv'\ndf_train = pd.read_csv(train_url)\ndf_test = pd.read_csv(test_url)\nstop_words_df = pd.read_excel('/kaggle/input/bangla-stopwords/stopwords_bangla.xlsx',index_col=False)","metadata":{"id":"b0560ae3","papermill":{"duration":0.132745,"end_time":"2023-07-25T16:06:53.244675","exception":false,"start_time":"2023-07-25T16:06:53.111930","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:47:09.760222Z","iopub.execute_input":"2023-09-11T00:47:09.760792Z","iopub.status.idle":"2023-09-11T00:47:10.465621Z","shell.execute_reply.started":"2023-09-11T00:47:09.760756Z","shell.execute_reply":"2023-09-11T00:47:10.464674Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"STOPWORDS = set([word.strip() for word in stop_words_df['words']])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:47:10.468235Z","iopub.execute_input":"2023-09-11T00:47:10.468980Z","iopub.status.idle":"2023-09-11T00:47:10.482782Z","shell.execute_reply.started":"2023-09-11T00:47:10.468923Z","shell.execute_reply":"2023-09-11T00:47:10.481740Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess(x):\n    html_pattern = re.compile('<.*?>')\n    x = html_pattern.sub(r'', x)\n    x = \" \".join([word for word in str(x).split() if word not in STOPWORDS])\n    return x\ndf_train['Comment'] = df_train['Comment'].apply(lambda x: preprocess(x))\ndf_test['Comment'] = df_test['Comment'].apply(lambda x:preprocess(x))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:47:10.484390Z","iopub.execute_input":"2023-09-11T00:47:10.485008Z","iopub.status.idle":"2023-09-11T00:47:10.544577Z","shell.execute_reply.started":"2023-09-11T00:47:10.484974Z","shell.execute_reply":"2023-09-11T00:47:10.543703Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nallcats = set(df_train['Category'].dropna().tolist())\nallcats.add('Correct')\nlabeldict = {}\ncounter = 0\nfor i in allcats:\n    labeldict[i] = counter\n    counter += 1\nlabeldict","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:47:10.546124Z","iopub.execute_input":"2023-09-11T00:47:10.546809Z","iopub.status.idle":"2023-09-11T00:47:10.557906Z","shell.execute_reply.started":"2023-09-11T00:47:10.546778Z","shell.execute_reply":"2023-09-11T00:47:10.556255Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'Correct': 0,\n 'Grammatical': 1,\n 'Multiple Errors': 2,\n 'Spelling': 3,\n 'Code Switching': 4}"},"metadata":{}}]},{"cell_type":"code","source":"def manage(x):\n    if x in labeldict:\n        return labeldict[x]\n    else:\n        return labeldict['Correct']\ndf_train['Category'] = df_train['Category'].apply(lambda x:manage(x))\ndf_test['Category'] = df_test['Category'].apply(lambda x:manage(x))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T00:47:10.559613Z","iopub.execute_input":"2023-09-11T00:47:10.560010Z","iopub.status.idle":"2023-09-11T00:47:10.577831Z","shell.execute_reply.started":"2023-09-11T00:47:10.559978Z","shell.execute_reply":"2023-09-11T00:47:10.576980Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"data_no = 5\n\n# Prepare the training data\ntrain_texts = df_train['Comment'].tolist()\ntrain_labels = df_train['Category'].tolist()\n\ntest_texts = df_test['Comment'].tolist()\ntest_labels = df_test['Category'].tolist()","metadata":{"id":"6b9dc3e4","papermill":{"duration":0.018204,"end_time":"2023-07-25T16:06:53.268005","exception":false,"start_time":"2023-07-25T16:06:53.249801","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:47:10.579457Z","iopub.execute_input":"2023-09-11T00:47:10.580360Z","iopub.status.idle":"2023-09-11T00:47:10.589099Z","shell.execute_reply.started":"2023-09-11T00:47:10.580329Z","shell.execute_reply":"2023-09-11T00:47:10.588123Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Tokenize and encode the training texts\ntrain_encodings = tokenizer(train_texts, truncation=True, max_length=128,\n        padding='max_length', return_tensors = 'pt')\n\n# Convert the labels to tensors\ntrain_labels = torch.tensor(train_labels)\n\n# Create a PyTorch dataset\ntrain_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'],\n                                               train_encodings['attention_mask'],\n                                               train_labels)\n\n# Create a data loader\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n\nmodel = model.to(device)","metadata":{"id":"c68abf8e","outputId":"fc006e00-bc36-49f7-9041-3cc6a300504b","papermill":{"duration":11.003131,"end_time":"2023-07-25T16:07:04.276102","exception":false,"start_time":"2023-07-25T16:06:53.272971","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:47:10.590228Z","iopub.execute_input":"2023-09-11T00:47:10.590556Z","iopub.status.idle":"2023-09-11T00:47:20.909769Z","shell.execute_reply.started":"2023-09-11T00:47:10.590525Z","shell.execute_reply":"2023-09-11T00:47:20.908715Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom sklearn.metrics import accuracy_score\n\n# Set the model to training mode\nmodel.train()\n\n# Define the optimizer and loss function\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nlosses = []\naccuracies = []  # To store accuracy per epoch\nnum_epochs = 5\n# Training loop\nfor epoch in tqdm(range(num_epochs)):  # Number of training epochs\n    running_loss = 0.0\n    predicted_labels = []  # To store predicted labels for accuracy calculation\n    true_labels = []  # To store true labels for accuracy calculation\n\n    for batch in tqdm(train_loader):\n        input_ids = batch[0].to(device)\n        attention_mask = batch[1].to(device)\n        labels = batch[2].to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n        # Convert logits to predicted labels\n        _, predicted = torch.max(logits, dim=1)\n        predicted_labels.extend(predicted.cpu().tolist())\n        true_labels.extend(labels.cpu().tolist())\n\n    epoch_loss = running_loss / len(train_loader)\n    losses.append(epoch_loss)\n\n    # Calculate and store accuracy\n    accuracy = accuracy_score(true_labels, predicted_labels)\n    accuracies.append(accuracy)\n\n    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {accuracy:.4f}')\n\n# Save the model\ntorch.save(model.state_dict(), 'model.pth')\n","metadata":{"id":"eedb3a9c","outputId":"81f0d82e-5d90-4271-e5cf-71638bf8bc98","papermill":{"duration":668.41198,"end_time":"2023-07-25T16:18:12.693572","exception":false,"start_time":"2023-07-25T16:07:04.281592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T00:47:20.913332Z","iopub.execute_input":"2023-09-11T00:47:20.913782Z","iopub.status.idle":"2023-09-11T01:04:08.352170Z","shell.execute_reply.started":"2023-09-11T00:47:20.913748Z","shell.execute_reply":"2023-09-11T01:04:08.351001Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ad7b14b00bc410abd11369976a982d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6247ea8cda5243e6a404a3f461b92c88"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5 - Loss: 1.1574 - Accuracy: 0.5700\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93878bce0e44ab39afacd8970c6dd66"}},"metadata":{}},{"name":"stdout","text":"Epoch 2/5 - Loss: 1.0007 - Accuracy: 0.6264\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15d32704e1e84f43a4826d7c94f1573b"}},"metadata":{}},{"name":"stdout","text":"Epoch 3/5 - Loss: 0.8826 - Accuracy: 0.6802\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f3336f600904075ba0f144054f8f120"}},"metadata":{}},{"name":"stdout","text":"Epoch 4/5 - Loss: 0.8011 - Accuracy: 0.7119\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/502 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2754f005c0e4c67bb1d818ed0f87f6f"}},"metadata":{}},{"name":"stdout","text":"Epoch 5/5 - Loss: 0.7421 - Accuracy: 0.7377\n","output_type":"stream"}]},{"cell_type":"code","source":"#dgfdgdfgdgffdgdfd1212jhkhk","metadata":{"papermill":{"duration":0.014424,"end_time":"2023-07-25T16:18:12.713695","exception":false,"start_time":"2023-07-25T16:18:12.699271","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T01:04:08.353971Z","iopub.execute_input":"2023-09-11T01:04:08.354342Z","iopub.status.idle":"2023-09-11T01:04:08.359834Z","shell.execute_reply.started":"2023-09-11T01:04:08.354310Z","shell.execute_reply":"2023-09-11T01:04:08.358915Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n\ndef predict_labels(text):\n    train_encodings = tokenizer(text, truncation=True, max_length=128,\n        padding='max_length', return_tensors = 'pt')\n    input_ids = train_encodings['input_ids'].to(device)\n    attention_mask = train_encodings['attention_mask'].to(device)\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Disable gradient calculation\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n\n    logits = outputs.logits\n    probabilities = torch.softmax(logits, dim=1)\n    predicted_class = torch.argmax(probabilities, dim=1)\n    \n\n    return predicted_class.item(), probabilities[:,1].item()","metadata":{"id":"1243273c","papermill":{"duration":0.69644,"end_time":"2023-07-25T16:18:13.415572","exception":false,"start_time":"2023-07-25T16:18:12.719132","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T01:04:08.361376Z","iopub.execute_input":"2023-09-11T01:04:08.362076Z","iopub.status.idle":"2023-09-11T01:04:08.373086Z","shell.execute_reply.started":"2023-09-11T01:04:08.362043Z","shell.execute_reply":"2023-09-11T01:04:08.372244Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"predicted_labels = []\npredicted_probs = []\nfor text in tqdm(test_texts):\n    predicted_label, prob = predict_labels(text)\n    predicted_labels.append(predicted_label)\n    predicted_probs.append(prob)\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(test_labels, predicted_labels)\n# f1 = f1_score(test_labels, predicted_labels)\n# roc_auc = roc_auc_score(test_labels, predicted_probs)\n\nprint('Accuracy:', accuracy)\n# print('F1 Score:', f1)\n# print('ROC-AUC:', roc_auc)","metadata":{"id":"d57fe764","outputId":"d7e9495a-7096-413f-cc6e-0f3e69cdc327","papermill":{"duration":56.127329,"end_time":"2023-07-25T16:19:09.548653","exception":false,"start_time":"2023-07-25T16:18:13.421324","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T01:04:08.374538Z","iopub.execute_input":"2023-09-11T01:04:08.374893Z","iopub.status.idle":"2023-09-11T01:04:40.045665Z","shell.execute_reply.started":"2023-09-11T01:04:08.374844Z","shell.execute_reply":"2023-09-11T01:04:40.044489Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2010 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b67e94998b24433daf8795607eba1afd"}},"metadata":{}},{"name":"stdout","text":"Accuracy: 0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Accuracy:', accuracy)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-09-11T01:04:40.047066Z","iopub.execute_input":"2023-09-11T01:04:40.047443Z","iopub.status.idle":"2023-09-11T01:04:40.053189Z","shell.execute_reply.started":"2023-09-11T01:04:40.047408Z","shell.execute_reply":"2023-09-11T01:04:40.052114Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Accuracy: 0.7\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, classification_report\n\nprint('\\nThe Classification Report is as follows\\n')\nprint(classification_report(test_labels, predicted_labels, digits = 4))","metadata":{"papermill":{"duration":0.031899,"end_time":"2023-07-25T16:19:09.586107","exception":false,"start_time":"2023-07-25T16:19:09.554208","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-09-11T01:04:40.054841Z","iopub.execute_input":"2023-09-11T01:04:40.055462Z","iopub.status.idle":"2023-09-11T01:04:40.090229Z","shell.execute_reply.started":"2023-09-11T01:04:40.055429Z","shell.execute_reply":"2023-09-11T01:04:40.089099Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nThe Classification Report is as follows\n\n              precision    recall  f1-score   support\n\n           0     0.7631    0.8323    0.7962      1157\n           1     0.0000    0.0000    0.0000       128\n           2     0.2727    0.0435    0.0750        69\n           3     0.5934    0.6827    0.6349       498\n           4     0.6159    0.6392    0.6273       158\n\n    accuracy                         0.7000      2010\n   macro avg     0.4490    0.4396    0.4267      2010\nweighted avg     0.6440    0.7000    0.6675      2010\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}